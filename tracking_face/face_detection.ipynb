{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUyE_bN-qia3",
        "outputId": "1b69b92a-9aed-4f20-b77b-51171a0e0afb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "udf3tWK_qj7M",
        "outputId": "ea9718ee-ee0a-41fb-a0d2-0b973b1a6299"
      },
      "outputs": [],
      "source": [
        "!pip install mediapipe opencv-python pandas face-detection-tflite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBsAvfb0qnIC"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "from fdlite import FaceDetection, FaceDetectionModel\n",
        "import pandas as pd\n",
        "from collections import deque\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2M4ckjpx2q1"
      },
      "outputs": [],
      "source": [
        "def initialize_face_detector(min_detection_confidence=0.6):\n",
        "    return mp.solutions.face_detection.FaceDetection(min_detection_confidence=min_detection_confidence)\n",
        "\n",
        "def process_frame(face_detection, frame):\n",
        "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    results = face_detection.process(image_rgb)\n",
        "    return results\n",
        "\n",
        "def extract_bbox(detection, frame_shape):\n",
        "    bboxC = detection.location_data.relative_bounding_box\n",
        "    ih, iw, _ = frame_shape\n",
        "    bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
        "    x, y, w = bbox[:3]\n",
        "    h = bbox[3] if len(bbox) == 4 else 0\n",
        "    center_x = x + w / 2\n",
        "    center_y = y + h / 2\n",
        "    return center_x, center_y, w, h\n",
        "\n",
        "def smooth_coordinates(coords, smooth_factor=5):\n",
        "    smoothed_coords = []\n",
        "    for coord in zip(*coords):\n",
        "        smoothed_coords.append(np.convolve(coord, np.ones(smooth_factor) / smooth_factor, mode='valid'))\n",
        "    return zip(*smoothed_coords)\n",
        "\n",
        "def video_process(video_path, output_video):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    frame_count = 0\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    out = cv2.VideoWriter(output_video, fourcc, frame_rate, (frame_width, frame_height))\n",
        "\n",
        "    face_detector = FaceDetection(model_type=FaceDetectionModel.BACK_CAMERA) # using fdlite\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_count += 1\n",
        "        results = face_detector(frame)\n",
        "\n",
        "        if results and len(results) == 1:\n",
        "            out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    print(f\"Output video saved to {output_video}\")\n",
        "\n",
        "def track_faces(video_path, result_csv_path, result_video_path, change_threshold=65, smooth_factor=3, min_duration=3, min_detection_confidence=0.6):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    frame_count = 0\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    out = cv2.VideoWriter(result_video_path, fourcc, frame_rate, (frame_width, frame_height))\n",
        "\n",
        "    tracking_data = []\n",
        "    current_id = 1\n",
        "    start_time = None\n",
        "    last_bbox = None\n",
        "    colors = {}\n",
        "    bbox_history = deque(maxlen=smooth_factor)\n",
        "\n",
        "    face_detector = initialize_face_detector(min_detection_confidence)\n",
        "\n",
        "    with face_detector:\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            frame_count += 1\n",
        "            current_time = frame_count / frame_rate\n",
        "            results = process_frame(face_detector, frame)\n",
        "\n",
        "            if results.detections:\n",
        "                if len(results.detections) == 1:\n",
        "                    detection = results.detections[0]\n",
        "                    center_x, center_y, width, height = extract_bbox(detection, frame.shape)\n",
        "\n",
        "                    bbox_history.append((center_x, center_y, width, height))\n",
        "                    if len(bbox_history) >= smooth_factor:\n",
        "                        smoothed_coords = smooth_coordinates(bbox_history, smooth_factor)\n",
        "                        center_x, center_y, width, height = next(smoothed_coords)\n",
        "\n",
        "                    if start_time is None:\n",
        "                        start_time = current_time\n",
        "\n",
        "                    if last_bbox is not None:\n",
        "                        last_center_x, last_center_y, last_width, last_height = last_bbox\n",
        "                        if abs(center_x - last_center_x) > change_threshold or abs(center_y - last_center_y) > change_threshold:\n",
        "                            current_id += 1\n",
        "                            start_time = current_time\n",
        "\n",
        "                    last_bbox = (center_x, center_y, width, height)\n",
        "\n",
        "                    if current_id not in colors:\n",
        "                        colors[current_id] = (int(current_id * 50 % 256), int(current_id * 80 % 256), int(current_id * 110 % 256))\n",
        "\n",
        "                    color = colors[current_id]\n",
        "\n",
        "                    cv2.rectangle(frame, (int(center_x - width / 2), int(center_y - height / 2)),\n",
        "                                  (int(center_x + width / 2), int(center_y + (height+40) / 2)), color, 2)\n",
        "                    cv2.putText(frame, f'ID: {current_id}', (int(center_x - width / 2), int(center_y - height / 2) - 10),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
        "                    cv2.putText(frame, f'Frame: {frame_count}', (int(center_x - width / 2), int(center_y - height / 2) - 60),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
        "\n",
        "                    tracking_data.append({\n",
        "                        'ID': current_id,\n",
        "                        'frame': frame_count,\n",
        "                        'start_time': start_time,\n",
        "                        'end_time': current_time,\n",
        "                        'bbox': [center_x, center_y, width, height]\n",
        "                    })\n",
        "                else:\n",
        "                    if len(tracking_data) > 0 and tracking_data[-1]['ID'] == current_id:\n",
        "                        current_id += 1\n",
        "                        start_time = None\n",
        "                        last_bbox = None\n",
        "                        bbox_history.clear()\n",
        "            else:\n",
        "                if len(tracking_data) > 0 and tracking_data[-1]['ID'] == current_id:\n",
        "                    current_id += 1\n",
        "                    start_time = None\n",
        "                    last_bbox = None\n",
        "                    bbox_history.clear()\n",
        "\n",
        "            out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    # Filter out IDs with a duration less than min_duration\n",
        "    filtered_data = []\n",
        "    for data in tracking_data:\n",
        "        duration = data['end_time'] - data['start_time']\n",
        "        if duration >= min_duration:\n",
        "            filtered_data.append(data)\n",
        "\n",
        "    df = pd.DataFrame(filtered_data)\n",
        "    df.to_csv(result_csv_path, index=False)\n",
        "\n",
        "    print(f\"Tracking data saved to {result_csv_path}\")\n",
        "    print(f\"Output video saved to {result_video_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfKYSn64O59g",
        "outputId": "07bcef63-472c-46d5-c4ea-0f15454b054c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output video saved to /content/drive/MyDrive/ColabDataset/LipReading/data/video_output/video01.mp4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
            "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tracking data saved to /content/drive/MyDrive/ColabDataset/LipReading/data/result/result_csv/video01.csv\n",
            "Output video saved to /content/drive/MyDrive/ColabDataset/LipReading/data/result/result_video/video01.mp4\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    video_path = '/content/drive/MyDrive/ColabDataset/LipReading/data/video_raw/video01.mov'\n",
        "    output_video = '/content/drive/MyDrive/ColabDataset/LipReading/data/video_output/video01.mp4'\n",
        "    result_csv_path = '/content/drive/MyDrive/ColabDataset/LipReading/data/result/result_csv/video01.csv'\n",
        "    result_video_path = '/content/drive/MyDrive/ColabDataset/LipReading/data/result/result_video/video01.mp4'\n",
        "    change_threshold = 65\n",
        "    smooth_factor = 3\n",
        "    min_duration = 3\n",
        "    min_detection_confidence = 0.6\n",
        "\n",
        "    video_process(video_path, output_video)\n",
        "    track_faces(output_video, result_csv_path, result_video_path, change_threshold, smooth_factor, min_duration, min_detection_confidence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivDr6Kym95dy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "TUS7x3miH-bm",
        "vsdbDbrrg-9_",
        "fM1AKDvBrkk5",
        "JxQ-MuzSoJwY"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
